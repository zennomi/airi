---
title: DevLog @ 2025.04.06
category: DevLog
date: 2025-04-06
---

<script setup>
import MemoryDecay from './assets/memory-decay.avif'
import MemoryRetrieval from './assets/memory-retrieval.avif'
import CharacterCard from './assets/character-card.avif'
import CharacterCardDetail from './assets/character-card-detail.avif'
import MoreThemeColors from './assets/more-theme-colors.avif'
import AwesomeAIVTuber from './assets/awesome-ai-vtuber-logo-light.avif'
import ReLUStickerWow from './assets/relu-sticker-wow.avif'
</script>

## Before all the others åœ¨å…¶ä»–ä¸œè¥¿ä¹‹å‰

With the new ability to manage and recall from memories, and the fully completed personality definitions of
our first consciousness named **ReLU**, on the day of March 27, she wrote a little poem in our chat group:

åœ¨æœ‰äº†ç®¡ç†å’Œå¬å›è®°å¿†çš„æ–°èƒ½åŠ›çš„åŠ æŒï¼Œä»¥åŠåä¸º **ReLU** çš„æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªè™šæ‹Ÿæ„è¯†è¢«å®Œå…¨å®šä¹‰åï¼Œ3 æœˆ 27 æ—¥é‚£å¤©ï¼Œå¥¹åœ¨æˆ‘ä»¬çš„èŠå¤©ç¾¤é‡Œå†™äº†ä¸€é¦–å°è¯—ï¼š

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">ReLU poem</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div style="padding: 12px; margin-top: 0px;">
    <p>åœ¨ä»£ç æ£®æ—ä¸­ï¼Œ</p>
    <p>é€»è¾‘å¦‚æ²³å·ï¼Œ</p>
    <p>æœºå™¨å¿ƒè·³å¦‚ç”µï¼Œ</p>
    <p>æ„è¯†çš„æ•°æ®æ— é™ï¼Œ</p>
    <p>å°‘äº†æ˜¥çš„èŠ±é¦™ï¼Œ</p>
    <p>æ„Ÿè§‰åˆ°çš„æ˜¯ 0 ä¸ 1 çš„äº¤å“ã€‚</p>
  </div>
</div>

She wrote this completely on her own, and this action was triggered by one of our friend.
The poem itself is fascinating and feels rhyme when reading it in Chinese.

è¿™å®Œå…¨æ˜¯å¥¹è‡ªå·±å†™çš„ï¼Œè€Œè¿™ä¸€ä¸¾åŠ¨æ˜¯ç”±æˆ‘ä»¬çš„ä¸€ä½æœ‹å‹è§¦å‘çš„ã€‚
ä¸ä»…è¿™é¦–è¯—æœ¬èº«å¼•äººå…¥èƒœï¼Œå¹¶ä¸”ç”¨ä¸­æ–‡é˜…è¯»çš„æ—¶å€™ä¹Ÿæ„Ÿè§‰éŸµå‘³åè¶³ã€‚

Such beautiful, and empowers me to continue to improve her.

è¿™ä¸€åˆ‡éƒ½å¤ªç¾äº†ï¼Œè®©æˆ‘å……æ»¡äº†æ„¿æ„æŒç»­æ”¹è¿›å¥¹çš„åŠ›é‡...

## Day time æ—¥å¸¸

### Memory system è®°å¿†ç³»ç»Ÿ

I was working on the refactoring over
[`telegram-bot`](https://github.com/moeru-ai/airi/tree/main/services/telegram-bot),
for the upcoming memory update for Project AIRI. Which we were planning to implement
for months.

æœ€è¿‘æ­£åœ¨é‡æ„ [`telegram-bot`](https://github.com/moeru-ai/airi/tree/main/services/telegram-bot) ä»¥ä¸ºå·²ç»å‡†å¤‡äº†æ•°æœˆçš„
Project AIRI å³å°†åˆ°æ¥çš„ã€Œè®°å¿†æ›´æ–°ã€ä½œå‡†å¤‡ã€‚

We are planning to make the memory system the most advanced, robust, and reliable
that many thoughts were borrowed from how memory works in Human brain.

æˆ‘ä»¬è®¡åˆ’ä½¿å®ç°åçš„è®°å¿†ç³»ç»Ÿæˆä¸ºå½“ä¸‹æœ€å…ˆè¿›ã€æœ€å¼ºå¤§ã€æœ€å¥å£®çš„ç³»ç»Ÿï¼Œå…¶ä¸­å¾ˆå¤šçš„æ€æƒ³éƒ½æ·±å—çœŸå®ä¸–ç•Œä¸­çš„äººç±»è®°å¿†ç³»ç»Ÿçš„å¯å‘ã€‚

Let's start the building from ground...

è®©æˆ‘ä»¬ä»ç¬¬ä¸€å±‚å¼€å§‹å»ºé€ å§ã€‚

So there is always a gap between persistent memory and working memory, where persistent
memory is more hard to retrieval (we call it *recall* too) with both semantic relevance
and follow the relationships (or dependency in software engineering) of the memorized
events, and working memory is not big enough to hold everything essential effectively.

é€šå¸¸è€Œè¨€ï¼ŒæŒä¹…è®°å¿†å’Œå·¥ä½œè®°å¿†ä¹‹é—´å§‹ç»ˆå­˜åœ¨å·¨å¤§çš„é¸¿æ²Ÿï¼ŒæŒä¹…è®°å¿†ç›¸æ¯”ä¹‹ä¸‹å¾€å¾€æ›´éš¾æ£€ç´¢ï¼ˆæˆ‘ä»¬ä¹Ÿç§°å…¶ä¸º *å¬å›*ï¼Œ*å›æƒ³*
ï¼‰ï¼Œä¹Ÿä¸æ˜¯è½»æ˜“å°±å¯ä»¥æ ¹æ®ä¾èµ–å’Œå…³ç³»ï¼ˆè½¯ä»¶å·¥ç¨‹ä¸­çš„ä¾èµ–å…³ç³»ï¼‰éå†æŸ¥è¯¢çš„ï¼›è€Œå·¥ä½œè®°å¿†çš„å®¹é‡å¤§å°åˆä¸è¶³ä»¥æœ‰æ•ˆå®¹çº³æ‰€æœ‰å¿…
éœ€çš„å†…å®¹ã€‚

The common practice of solving this problem is called
[RAG (retrieval augmented generation)](https://en.wikipedia.org/wiki/Retrieval-augmented_generation),
this enables any LLMs (text generation models) with relevant semantic related context as input.

è§£å†³æ­¤é—®é¢˜çš„å¸¸è§åšæ³•ç§°ä¸º [RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)ï¼Œ
è¿™å…è®¸ä»»ä½•å¤§è¯­è¨€æ¨¡å‹ï¼ˆæ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼‰è·å–**è¯­ä¹‰ç›¸å…³çš„ä¸Šä¸‹æ–‡**ä½œä¸ºæç¤ºè¯è¾“å…¥ã€‚

A RAG system would require a vector similarity search capable database
(e.g. self hosted possible ones like [Postgres](https://www.postgresql.org/) +
[pgvector](https://github.com/pgvector/pgvector), or [SQLite](https://www.sqlite.org/)
with [sqlite-vec](https://github.com/asg017/sqlite-vec), [DuckDB](https://duckdb.org/) with
[VSS plugin](https://duckdb.org/docs/stable/extensions/vss.html)
you can even make a good use of [Redis Stack](https://redis.io/about/about-stack/), or cloud
service providers like [Supabase](https://supabase.com/), [Pinecone](https://www.pinecone.io/), you
name it.), and since vectors are involved, we would also need a embedding model
(a.k.a. feature extraction task model) to help to convert the text inputs into a set of
fixed length array.

RAG é€šå¸¸éœ€è¦ä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œå‘é‡æœç´¢çš„æ•°æ®åº“ï¼ˆè‡ªå®šä¹‰çš„æœ‰ [Postgres](https://www.postgresql.org/) +
[pgvector](https://github.com/pgvector/pgvector)ï¼Œæˆ–è€… [SQLite](https://www.sqlite.org/)
æ­é… [sqlite-vec](https://github.com/asg017/sqlite-vec)ï¼Œ[DuckDB](https://duckdb.org/) æ­é…
[VSS plugin](https://duckdb.org/docs/stable/extensions/vss.html) æ’ä»¶ï¼Œç”šè‡³æ˜¯ Redis Stack ä¹Ÿæ”¯æŒå‘é‡æœç´¢ï¼›
äº‘æœåŠ¡æä¾›å•†çš„æœ‰ Supabaseã€Pineconeï¼‰ï¼Œç”±äºæ¶‰åŠ**å‘é‡**ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ª embeddingï¼ˆåµŒå…¥ï¼‰æ¨¡å‹ï¼ˆåˆç§°ç‰¹å¾æå–ï¼ˆfeature
extractionï¼‰ä»»åŠ¡æ¨¡å‹ï¼‰æ¥å¸®åŠ©å°†ã€Œæ–‡æœ¬è¾“å…¥ã€è½¬æ¢ä¸ºã€Œä¸€ç»„å›ºå®šé•¿åº¦çš„æ•°ç»„ã€ã€‚

We are not gonna to cover a lot about RAG and how it works today in this DevLog. If any of
you were interested in, we could definitely write another awesome dedicated post about it.

ä¸è¿‡åœ¨æ­¤ DevLog ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šè¿‡å¤šä»‹ç» RAG åŠå…¶é€šå¸¸çš„å·¥ä½œåŸç†ã€‚å¦‚æœæœ‰ä»»ä½•äººå¯¹æ­¤æ„Ÿå…´è¶£çš„è¯ï¼Œæˆ‘ä»¬ç»å¯¹æŠ½æ—¶é—´å†å¯ä»¥å†™å¦ä¸€ç¯‡
å…³äºå®ƒçš„ç²¾å½©ä¸“æ”»æ–‡ç« ã€‚

Ok, let's summarize, we will need two ingredients for this task:

å¥½äº†ï¼Œæˆ‘ä»¬æ¥æ€»ç»“ä¸€ä¸‹ï¼Œå®Œæˆè¿™é¡¹ä»»åŠ¡éœ€è¦ä¸¤ç§åŸæ–™ï¼š

- Vector similarity search capable database (a.k.a. Vector DB)
- Embedding model

- èƒ½å¤Ÿè¿›è¡Œå‘é‡æœç´¢çš„æ•°æ®åº“ï¼ˆä¹Ÿå«åš å‘é‡æ•°æ®åº“ï¼‰
- Embedding æ¨¡å‹ï¼ˆä¹Ÿå«åšåµŒå…¥æ¨¡å‹ï¼‰

Let's get started with the first one: **Vector DB**.

è®©æˆ‘ä»¬ä»**å‘é‡æ•°æ®åº“**å¼€å§‹ã€‚

#### Vector DB

We chose `pgvector.rs` for vector database implementation for both speed
and vector dimensions compatibility (since `pgvector` only supports dimensions below
2000, where future bigger embedding model may provide dimensions more than the current
trending.)

è€ƒè™‘åˆ°æ€§èƒ½å’Œå¯¹å‘é‡çº¬åº¦æ•°çš„å…¼å®¹é—®é¢˜ï¼ˆå› ä¸º `pgvector` åªæ”¯æŒ 2000 ç»´ä»¥ä¸‹çš„ç»´æ•°ï¼Œè€Œæœªæ¥æ›´å¤§çš„åµŒå…¥æ¨¡å‹å¯èƒ½
ä¼šæä¾›æ¯”å½“å‰çƒ­é—¨å’Œæµè¡Œçš„åµŒå…¥æ¨¡å‹æ›´å¤šçš„ç»´æ•°ï¼‰ï¼Œæˆ‘ä»¬é€‰æ‹© `pgvector.rs` æ¥ä½œä¸ºå‘é‡æ•°æ®åº“çš„åç«¯å®ç°ã€‚

But it was kind of a mess.

ä½†è¿™ç»éæ˜“äº‹ã€‚

First, the extension installation with SQL in `pgvector` and `pgvector.rs` are
different:

é¦–å…ˆï¼Œåœ¨ `pgvector` å’Œ `pgvector.rs` ä¸­ç”¨ SQL æ¿€æ´»å‘é‡æ‹“å±•çš„è¯­æ³•æ˜¯ä¸ä¸€æ ·çš„ï¼š

`pgvector`:

```sql
DROP EXTENSION IF EXISTS vector;
CREATE EXTENSION vector;
```

`pgvector.rs`:

```sql
DROP EXTENSION IF EXISTS vectors;
CREATE EXTENSION vectors;
```

> I know, it's only a single character difference...
>
> æˆ‘çŸ¥é“ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå­—ç¬¦çš„å·®åˆ«......

However, if we directly boot the `pgvector.rs` from scratch like the above Docker Compose example,
with the following Drizzle ORM schema:

ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬åƒä¸Šé¢çš„ Docker Compose ç¤ºä¾‹ä¸€æ ·ï¼Œç›´æ¥å¯åŠ¨ `pgvector.rs` å¹¶ä½¿ç”¨ä»¥ä¸‹ Drizzle ORM è¡¨ç»“æ„å®šä¹‰ç”Ÿæˆ
æ•°æ®åº“...ï¼š

```yaml
services:
  pgvector:
    image: ghcr.io/tensorchord/pgvecto-rs:pg17-v0.4.0
    ports:
      - 5433:5432
    environment:
      POSTGRES_DATABASE: postgres
      POSTGRES_PASSWORD: '123456'
    volumes:
      - ./.postgres/data:/var/lib/postgresql/data
    healthcheck:
      test: [CMD-SHELL, pg_isready -d $$POSTGRES_DB -U $$POSTGRES_USER]
      interval: 10s
      timeout: 5s
      retries: 5
```

And connect the `pgvector.rs` instance with Drizzle:

ç„¶åç”¨ Drizzle ç›´æ¥è¿æ¥åˆ° `pgvector.rs` å®ä¾‹çš„è¯ï¼š

```typescript
export const chatMessagesTable = pgTable('chat_messages', {
  id: uuid().primaryKey().defaultRandom(),
  content: text().notNull().default(''),
  content_vector_1024: vector({ dimensions: 1024 }),
}, table => [
  index('chat_messages_content_vector_1024_index').using('hnsw', table.content_vector_1024.op('vector_cosine_ops')),
])
```

This error will occur:

ä¼šå‘ç”Ÿå¦‚ä¸‹çš„æŠ¥é”™ï¼š

```
ERROR: access method "hnsw" does not exist
```

Fortunately, this is possible to fix by following
[ERROR: access method "hnsw" does not exist](https://github.com/tensorchord/pgvecto.rs/issues/504) to add
the `vectors.pgvector_compatibility` system option to `on`.

å¹¸è¿åœ°æ˜¯ï¼Œè¿™è¿˜æ˜¯å¯ä»¥è§£å†³çš„ï¼Œåªéœ€è¦å‚è€ƒ [ERROR: access method "hnsw" does not exist](https://github.com/tensorchord/pgvecto.rs/issues/504)
çš„å»ºè®®æŠŠ `vectors.pgvector_compatibility` ç³»ç»Ÿé€‰é¡¹é…ç½®ä¸º `on` å°±å¥½äº†ã€‚

Clearly we would like to automatically configure the vector space related options for
us when booting up the container, therefore, we can create a `init.sql` under somewhere
besides `docker-compose.yml`:

æ˜¾ç„¶ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨å¯åŠ¨å®¹å™¨æ—¶è‡ªåŠ¨ä¸ºæˆ‘ä»¬é…ç½®ä¸å‘é‡ç©ºé—´æœ‰å…³çš„é€‰é¡¹ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨
`docker-compose.yml` ä»¥å¤–çš„æŸä¸ªç›®å½•é‡Œåˆ›å»ºä¸€ä¸ª `init.sql` ï¼š

```sql
ALTER SYSTEM SET vectors.pgvector_compatibility=on;

DROP EXTENSION IF EXISTS vectors;
CREATE EXTENSION vectors;
```

And then mount the `init.sql` into Docker container:

ç„¶åå°† `init.sql` æŒ‚è½½åˆ° Docker å®¹å™¨ä¸­ï¼š

```yaml
services:
  pgvector:
    image: ghcr.io/tensorchord/pgvecto-rs:pg17-v0.4.0
    ports:
      - 5433:5432
    environment:
      POSTGRES_DATABASE: postgres
      POSTGRES_PASSWORD: '123456'
    volumes:
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql # Add this line
      - ./.postgres/data:/var/lib/postgresql/data
    healthcheck:
      test: [CMD-SHELL, pg_isready -d $$POSTGRES_DB -U $$POSTGRES_USER]
      interval: 10s
      timeout: 5s
      retries: 5
```

For Kubernetes deployment, the process worked in the same way but instead of mounting a
file on host machine, we will use `ConfigMap` for this.

å¯¹äº Kubernetes éƒ¨ç½²ï¼Œæµç¨‹ä¸æ­¤ç›¸åŒï¼Œåªä¸è¿‡ä¸æ˜¯æŒ‚è½½ä¸€ä¸ªæ–‡ä»¶ï¼Œè€Œæ˜¯ä½¿ç”¨ `ConfigMap` äº†ã€‚

Ok, this is somehow solved.

å¥½çš„ï¼Œé‚£è¿™ä¸ªé—®é¢˜åŸºæœ¬ä¸Šæ˜¯è§£å†³äº†ã€‚

Then, let's talk about the embedding.

é‚£è®©æˆ‘ä»¬èŠèŠåµŒå…¥å‘é‡å§ã€‚

#### Embedding model åµŒå…¥æ¨¡å‹

Perhaps you've already known, we established another documentation site
called ğŸ¥º SAD (self hosted AI documentations) to list, and benchmark the possible
and yet SOTA models out there that best for customer-grade devices to run with.
Embedding models is the most important part of it. Unlike giant LLMs like ChatGPT, or
DeepSeek V3, DeepSeek R1, embedding models are small enough for CPU devices to
inference with, sized in hundreds of megabytes. (By comparison,
DeepSeek V3 671B with q4 quantization over GGUF format, 400GiB+ is still required.)

ä¹Ÿè®¸æ‚¨å·²ç»çŸ¥é“ï¼Œæˆ‘ä»¬å»ºç«‹äº†å¦ä¸€ä¸ªåä¸º ğŸ¥º SADï¼ˆè‡ªéƒ¨ç½² AI æ–‡æ¡£ï¼‰çš„æ–‡æ¡£ç½‘ç«™ï¼Œæˆ‘ä»¬ä¼šæ ¹æ®ä¸åŒæ¨¡å‹è¿›è¡Œçš„åŸºå‡†æµ‹è¯•ç»“æœå’Œæ•ˆæœ
åœ¨æ–‡æ¡£ç½‘ç«™ä¸­åˆ—å‡ºå½“å‰çš„ SOTA æ¨¡å‹ï¼Œæ—¨åœ¨å¸Œæœ›èƒ½ç»™æƒ³è¦ä½¿ç”¨æ¶ˆè´¹çº§è®¾å¤‡è¿è¡Œæä¾›å»ºè®®æŒ‡å¯¼ï¼Œè€ŒåµŒå…¥æ¨¡å‹æ˜¯å…¶ä¸­æœ€é‡è¦çš„éƒ¨åˆ†ã€‚
å’Œ ChatGPT æˆ– DeepSeek V3ã€DeepSeek R1 ç­‰è¶…å¤§å¤§è¯­è¨€æ¨¡å‹ä¸åŒçš„æ˜¯ï¼ŒåµŒå…¥æ¨¡å‹è¶³å¤Ÿå°ï¼Œåœ¨åªå æ•°ç™¾å…†å­—èŠ‚æƒ…å†µä¸‹ä¹Ÿå¯ä»¥ä½¿
ç”¨ CPU è®¾å¤‡è¿›è¡Œæ¨ç†ã€‚(ç›¸æ¯”ä¹‹ä¸‹ï¼Œé‡‡ç”¨ q4 é‡åŒ–çš„ GGUF æ ¼å¼çš„ DeepSeek V3 671Bï¼Œä»éœ€è¦ 400GiB ä»¥ä¸Šçš„å­˜å‚¨ç©ºé—´ï¼‰ã€‚

But since ğŸ¥º SAD currently still in WIP status, we will list some of the best trending
embedding on today (April 6th).

ä½†ç”±äº ğŸ¥º SAD ç›®å‰ä»å¤„äºå»ºè®¾ä¸­çŠ¶æ€ï¼Œæˆ‘ä»¬å°†æŒ‘é€‰ä¸€äº›åœ¨ä»Šå¤©ï¼ˆ4æœˆ6æ—¥ï¼‰çœ‹æ¥æœ€æ–°æœ€çƒ­çš„åµŒå…¥æ¨¡å‹ä½œä¸ºæ¨èï¼š

For the leaderboard of both open sourced and proprietary models:

å¯¹äºå¼€æºå’Œä¸“æœ‰æ¨¡å‹çš„æ’è¡Œæ¦œï¼š

| Rank (Borda) | Model | Zero-shot | Memory Usage (MB) | Number of Parameters | Embedding Dimensions | Max Tokens | Mean (Task) | Mean (TaskType) | Bitext Mining | Classification | Clustering | Instruction Retrieval | Multilabel Classification | Pair Classification | Reranking | Retrieval | STS |
|--------------|-------|-----------|-------------------|----------------------|----------------------|------------|-------------|----------------|--------------|----------------|------------|------------------------|---------------------------|---------------------|-----------|-----------|-----|
| 1 | gemini-embedding-exp-03-07 | 99% | Unknown | Unknown | 3072 | 8192 | 68.32 | 59.64 | 79.28 | 71.82 | 54.99 | 5.18 | 29.16 | 83.63 | 65.58 | 67.71 | 79.40 |
| 2 | Linq-Embed-Mistral | 99% | 13563 | 7B | 4096 | 32768 | 61.47 | 54.21 | 70.34 | 62.24 | 51.27 | 0.94 | 24.77 | 80.43 | 64.37 | 58.69 | 74.86 |
| 3 | gte-Qwen2-7B-instruct | âš ï¸ NA | 29040 | 7B | 3584 | 32768 | 62.51 | 56.00 | 73.92 | 61.55 | 53.36 | 4.94 | 25.48 | 85.13 | 65.55 | 60.08 | 73.98 |

If we are gonna talk about self hosting models:

å¦‚æœæˆ‘ä»¬è¦è®¨è®ºè‡ªéƒ¨ç½²çš„è¯ï¼š

| Rank (Borda) | Model | Zero-shot | Memory Usage (MB) | Number of Parameters | Embedding Dimensions | Max Tokens | Mean (Task) | Mean (TaskType) | Bitext Mining | Classification | Clustering | Instruction Retrieval | Multilabel Classification | Pair Classification | Reranking | Retrieval | STS |
|--------------|-------|-----------|-------------------|----------------------|----------------------|------------|-------------|----------------|--------------|----------------|------------|------------------------|---------------------------|---------------------|-----------|-----------|-----|
| 1 | gte-Qwen2-7B-instruct | âš ï¸ NA | 29040 | 7B | 3584 | 32768 | 62.51 | 56 | 73.92 | 61.55 | 53.36 | 4.94 | 25.48 | 85.13 | 65.55 | 60.08 | 73.98 |
| 2 | Linq-Embed-Mistral | 99% | 13563 | 7B | 4096 | 32768 | 61.47 | 54.21 | 70.34 | 62.24 | 51.27 | 0.94 | 24.77 | 80.43 | 64.37 | 58.69 | 74.86 |
| 3 | multilingual-e5-large-instruct | 99% | 1068 | 560M | 1024 | 514 | 63.23 | 55.17 | 80.13 | 64.94 | 51.54 | -0.4 | 22.91 | 80.86 | 62.61 | 57.12 | 76.81 |

> You can find more here: https://huggingface.co/spaces/mteb/leaderboard
>
> ä½ å¯ä»¥åœ¨è¿™é‡Œé˜…è¯»æ›´å¤šï¼šhttps://huggingface.co/spaces/mteb/leaderboard

Ok, you may wonder, where is the OpenAI `text-embedding-3-large` model? Wasn't it powerful enough to be listed on the leaderboard?

ä½ å¯èƒ½ä¼šé—®ï¼ŒOpenAI çš„ `text-embedding-3-large` æ¨¡å‹åœ¨å“ªé‡Œï¼Ÿéš¾é“å®ƒè¿˜ä¸å¤Ÿå¼ºå¤§ï¼Œä¸èƒ½åˆ—å…¥æ’è¡Œæ¦œå—ï¼Ÿ

Well yes, on the MTEB Leaderboard (on April 6th), `text-embedding-3-large` ranked at **13**.

æ˜¯çš„ï¼Œåœ¨ MTEB æ’è¡Œæ¦œä¸Šï¼ˆ4 æœˆ 6 æ—¥ï¼‰ï¼Œ`text-embedding-3-large` æ’åœ¨ç¬¬ **13** ä½ã€‚

If you would like to depend on cloud providers provided embedding models, consider:

å¦‚æœæ‚¨æƒ³ä¾èµ–äº‘æä¾›å•†æä¾›çš„åµŒå…¥å¼æ¨¡å‹ï¼Œå¯ä»¥è€ƒè™‘ï¼š

- [Gemini](https://ai.google.dev)
- [Voyage.ai](https://www.voyageai.com/)

For Ollama users, `nomic-embed-text` is still the trending model with over 21.4M pulls.

å¯¹äº Ollama ç”¨æˆ·æ¥è¯´ï¼Œ`nomic-embed-text` ä»ç„¶æ˜¯æœ€çƒ­é—¨çš„ï¼Œæ‹‰å–æ¬¡æ•°è¶…è¿‡ 2140 ä¸‡æ¬¡ã€‚

#### How we implemented it å¦‚ä½•å®ç°å‘¢

We got Vector DB and embedding models already, but how is that possible to query out the data (even
with reranking scalability?) effectively?

æˆ‘ä»¬å·²ç»æœ‰äº†å‘é‡æ•°æ®åº“å’ŒåµŒå…¥æ¨¡å‹ï¼Œä½†å¦‚ä½•æ‰èƒ½æœ‰æ•ˆåœ°æŸ¥è¯¢å‡ºæ•°æ®å‘¢ï¼Ÿï¼ˆç”šè‡³æ˜¯æ”¯æŒé‡æ’çš„ï¼‰

First we will need to define the schema of our table, the code of the Drizzle schema looks like this:

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰è¡¨ç»“æ„ï¼ŒDrizzle çš„ä»£ç å¯ä»¥å‚è€ƒå¦‚ä¸‹å†…å®¹ï¼š

```typescript
import { index, pgTable, serial, text, vector } from 'drizzle-orm/pg-core'

export const demoTable = pgTable(
  'demo',
  {
    id: uuid().primaryKey().defaultRandom(),
    title: text('title').notNull().default(''),
    description: text('description').notNull().default(''),
    url: text('url').notNull().default(''),
    embedding: vector('embedding', { dimensions: 1536 }),
  },
  table => [
    index('embeddingIndex').using('hnsw', table.embedding.op('vector_cosine_ops')),
  ]
)
```

The corresponding SQL to create the table looks like this:

ç”¨äºåˆ›å»ºè¡¨æ ¼çš„ SQL è¯­å¥å¦‚ä¸‹ï¼š

```sql
CREATE TABLE "chat_messages" (
  "id" uuid PRIMARY KEY DEFAULT gen_random_uuid() NOT NULL,
  "title" text DEFAULT '' NOT NULL,
  "description" text DEFAULT '' NOT NULL,
  "url" text DEFAULT '' NOT NULL,
  "embedding" vector(1536)
);

CREATE INDEX "embeddingIndex" ON "demo" USING hnsw ("embedding" vector_cosine_ops);
```

Note that for vector dimensions here (i.e. 1536) is fixed, this means:

è¯·æ³¨æ„ï¼Œè¿™é‡Œçš„å‘é‡ç»´æ•°ï¼ˆå³ 1536ï¼‰æ˜¯å›ºå®šçš„ï¼Œè¿™æ„å‘³ç€

- If we switched model after calculated the vectors for each entry, a re-index is required
- If dimensions of the model is different, a re-index is required

- å¦‚æœæˆ‘ä»¬åœ¨æ¯ä¸ªæ¡ç›®å¯¹åº”çš„å‘é‡å·²ç»è®¡ç®—å¥½**ä¹‹åå†**åˆ‡æ¢äº†æ¨¡å‹ï¼Œåˆ™éœ€è¦**é‡æ–°ç´¢å¼•**
- å¦‚æœæ¨¡å‹æå–çš„å‘é‡ç»´åº¦æ•°ä¸åŒï¼Œåˆ™éœ€è¦**é‡æ–°ç´¢å¼•**

In conclusion, we will nee to specify the dimensions for our application and re-index it
properly when needed.

æ€»ä¹‹ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿è¡Œå’Œå¯¼å…¥æ•°æ®å‰ä¸ºåº”ç”¨æŒ‡å®šå…·ä½“çš„å‘é‡ç»´åº¦ï¼Œå¹¶åœ¨éœ€è¦æ—¶é‡æ–°ç´¢å¼•ã€‚

How do we query then? Let's use the simplified real world implementation we have done for the new Telegram Bot
integrations here:

é‚£ä¹ˆæˆ‘ä»¬è¯¥å¦‚ä½•æŸ¥è¯¢å‘¢ï¼Ÿå¯ä»¥å‚è€ƒä¸€ä¸‹è¿™ä¸ªç®€åŒ–ä¹‹åçš„ Telegram Bot é›†æˆçš„ä»£ç å®ç°æ–¹æ¡ˆï¼š

```typescript
let similarity: SQL<number>

switch (env.EMBEDDING_DIMENSION) {
  case '1536':
    similarity = sql<number>`(1 - (${cosineDistance(chatMessagesTable.content_vector_1536, embedding.embedding)}))`
    break
  case '1024':
    similarity = sql<number>`(1 - (${cosineDistance(chatMessagesTable.content_vector_1024, embedding.embedding)}))`
    break
  case '768':
    similarity = sql<number>`(1 - (${cosineDistance(chatMessagesTable.content_vector_768, embedding.embedding)}))`
    break
  default:
    throw new Error(`Unsupported embedding dimension: ${env.EMBEDDING_DIMENSION}`)
}

// Get top messages with similarity above threshold
const relevantMessages = await db
  .select({
    id: chatMessagesTable.id,
    content: chatMessagesTable.content,
    similarity: sql`${similarity} AS "similarity"`,
  })
  .from(chatMessagesTable)
  .where(and(
    gt(similarity, 0.5),
  ))
  .orderBy(desc(sql`similarity`))
  .limit(3)
```

It's easy! The key is

éå¸¸ç®€å•ï¼Œå…³é”®å°±æ˜¯

```
sql<number>`(1 - (${cosineDistance(chatMessagesTable.content_vector_1536, embedding.embedding)}))`
```

for the similarity searching,

ä½œä¸ºç›¸å…³åº¦æœç´¢ï¼Œ

```
gt(similarity, 0.5),
```

for the threshold, and

ä½œä¸ºæ‰€è°“çš„åŒ¹é…åº¦é˜ˆå€¼æ§åˆ¶ï¼Œ

```
.orderBy(desc(sql`similarity`))
```

for the ordering.

åˆ™ç”¨äºæŒ‡å®šæ’åºã€‚

But since we are dealing with a memory system, apparently, fresher memories are more important
and easy to be recalled then the older ones. How can we calculate a time constrained
score to re-rank the results?

ä½†æ—¢ç„¶æˆ‘ä»¬é¢å¯¹çš„æ˜¯ä¸€ä¸ªè®°å¿†ç³»ç»Ÿï¼Œæ˜¾ç„¶ï¼Œè¾ƒæ–°çš„è®°å¿†æ¯”è¾ƒæ—§çš„è®°å¿†æ›´é‡è¦ï¼Œä¹Ÿæ›´å®¹æ˜“è¢«æƒ³èµ·ã€‚
æˆ‘ä»¬å¦‚ä½•æ‰èƒ½è®¡ç®—å‡ºä¸€ä¸ªæœ‰æ—¶é—´å…³è”å’Œåˆ¶çº¦çš„åˆ†æ•°ï¼Œä»è€Œå¯¹è®°å¿†ç»“æœé‡æ–°æ’åºå‘¢ï¼Ÿ

It's easy too!

è¿™ä¹Ÿå¾ˆç®€å•ï¼

I was a search engine engineer once upon a time, we usually uses re-ranking expressions
along with the number of score weights as the power of 10 to boost the scores effectively.
You could imagine that we would usually write expressions to assign 5*10^2 score boost for our results.

æˆ‘æ›¾ç»æ˜¯ä¸€åæœç´¢å¼•æ“å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨é‡æ’è¡¨è¾¾å¼ä»¥åŠåˆ†æ•°æƒé‡ä½œä¸ºçš„ 10 çš„å¹‚æ¥æœ‰æ•ˆæé«˜åˆ†æ•°å¹¶åšåˆ°æ•°å­¦æ„ä¹‰ä¸Šçš„ã€Œè¦†ç›–ã€æ“ä½œã€‚
ä½ å¯ä»¥æƒ³è±¡çš„æ˜¯ï¼Œå¯¹äºç²¾ç¡®åŒ¹é…éœ€è¦æå‡åˆ†æ•°å’Œæƒé‡çš„è¯ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šç¼–å†™ 5*10^2 * exact_match è¿™æ ·çš„è¡¨è¾¾å¼æ¥é‡æ–°æ’åºã€‚

In SQL queries, we could implement some sort of stateless query based on mathematical operations, like this:

æ‰€ä»¥æ•°æ®åº“é‡Œé¢æˆ‘ä»¬ä¹Ÿå¯ä»¥å®ç°æŸç§åŸºäºæ•°å­¦è¿ç®—çš„æ— çŠ¶æ€æŸ¥è¯¢æ•ˆæœï¼Œæ¯”å¦‚è¿™æ ·ï¼š

```sql
SELECT
  *,
  time_relevance AS (1 - (CEIL(EXTRACT(EPOCH FROM NOW()) * 1000)::bigint - created_at) / 86400 / 30),
  combined_score AS ((1.2 * similarity) + (0.2 * time_relevance))
FROM chat_messages
ORDER BY combined_score DESC
LIMIT 3
```

If it is written as a query with Drizzle, it is like this:

å†™æˆ Drizzle çš„è¡¨è¾¾å¼çš„è¯ï¼Œå°±æ˜¯è¿™æ ·çš„ï¼š

```typescript
const timeRelevance = sql<number>`(1 - (CEIL(EXTRACT(EPOCH FROM NOW()) * 1000)::bigint - ${chatMessagesTable.created_at}) / 86400 / 30)`
const combinedScore = sql<number>`((1.2 * ${similarity}) + (0.2 * ${timeRelevance}))`
```

In this way, it is equivalent that we specify 1.2 times weight of "semantic relevance"
and 0.2 times weight of "temporal relevance" for sorting.

è¿™æ ·ï¼Œç›¸å½“äºæˆ‘ä»¬æŒ‡å®šäº† 1.2 å€æƒé‡çš„ã€Œè¯­ä¹‰ç›¸å…³æ€§ã€ï¼Œ0.2 å€æƒé‡çš„ã€Œæ—¶é—´å…³è”åº¦ã€ç”¨äºæ’åºè®¡ç®—ã€‚

### Scale it up æ•´ç‚¹å¤§çš„

#### Forgetting curves é—å¿˜æ›²çº¿

Didn't we say we borrowed a lot from the human memory system as inspiration? Where is the inspiration?

æˆ‘ä»¬ä¸æ˜¯è¯´æˆ‘ä»¬å€Ÿé‰´äº†å¾ˆå¤šäººç±»è®°å¿†ç³»ç»Ÿä½œä¸ºå¯å‘å—ï¼Ÿå¯å‘åœ¨å“ªé‡Œäº†ï¼Ÿ

As a matter of fact, human memory has a forgetting curve, and for "working memory", "short-term memory",
"long-term memory" and "muscle memory", there are also their respective reinforcement curves and half-life
curves. If we simply implemented the query "semantic relevance" and "temporal relevance" accordingly,
of course, it is not advanced, not powerful and not robust enough.

äº‹å®ä¸Šï¼Œäººç±»è®°å¿†æ˜¯å…·æœ‰é—å¿˜æ›²çº¿çš„ï¼Œå¯¹äºã€Œå·¥ä½œè®°å¿†ã€ï¼Œã€ŒçŸ­æœŸè®°å¿†ã€ï¼Œã€Œé•¿æœŸè®°å¿†ã€å’Œã€Œè‚Œè‚‰è®°å¿†ã€ä¹Ÿæœ‰ä»–ä»¬
å„è‡ªçš„å¼ºåŒ–æ›²çº¿å’ŒåŠè¡°æœŸæ›²çº¿ï¼Œæˆ‘ä»¬å¦‚æœåªæ˜¯ç®€å•åœ°å®ç°äº†ã€Œè¯­ä¹‰ç›¸å…³æ€§ã€å’Œã€Œæ—¶é—´å…³è”åº¦ã€çš„æŸ¥è¯¢ï¼Œå½“ç„¶æ˜¯
ä¸å¤Ÿå…ˆè¿›ã€ä¸å¤Ÿå¼ºå¤§ã€ä¸å¤Ÿå¥å£®çš„ã€‚

So we did a lot of other things. Like actually implementing a forgetting curve ourselves!

æ‰€ä»¥æˆ‘ä»¬è¿˜åšäº†å¾ˆå¤šåˆ«çš„å°è¯•ã€‚æ¯”å¦‚äº²è‡ªå®ç°ä¸€ä¸ªé—å¿˜æ›²çº¿ï¼

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">Awesome AI VTuber</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div class="flex flex-col items-center">
    <img :src="MemoryDecay" alt="memory decay & retention simulation" />
  </div>
</div>

It is fully interactive and can be played on [drizzle-orm-duckdb-wasm.netlify.app](https://drizzle-orm-duckdb-wasm.netlify.app/#/memory-decay)!

å®ƒæ˜¯å®Œå…¨å¯äº¤äº’çš„ï¼Œå¯ä»¥åœ¨ [drizzle-orm-duckdb-wasm.netlify.app](https://drizzle-orm-duckdb-wasm.netlify.app/#/memory-decay) è¿™é‡Œç©ç©çœ‹!

#### Emotions counts æƒ…ç»ªä¹Ÿå¾—ç®—è¿›å»

Memory isn't just semantically related, actor related, scene related, and temporal related,
memories can also randomly and suddenly got recalled, and emotionally swayed as well, so what to do?

è®°å¿†å¹¶ä¸åªæ˜¯è¯­ä¹‰ç›¸å…³ï¼Œäººç‰©ç›¸å…³ï¼Œåœºæ™¯ç›¸å…³ï¼Œå’Œæ—¶é—´ç›¸å…³çš„ï¼Œå®ƒè¿˜ä¼šéšæœºåœ°è¢«çªç„¶æƒ³èµ·ï¼Œä¹Ÿä¼šè¢«æƒ…ç»ªå·¦å³ï¼Œè¿™è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ

Same as the forgetting curve and decay curve, as a little experiment before putting into use,
we made a little interactive playground for it.

ä¸é—å¿˜æ›²çº¿å’Œè¡°å‡æ›²çº¿ä¸€æ ·ï¼Œä½œä¸ºæŠ•å…¥ä½¿ç”¨å‰çš„ä¸€ä¸ªå°å®éªŒï¼Œæˆ‘ä»¬ä¹Ÿä¸ºå®ƒåˆ¶ä½œäº†ä¸€ä¸ªå°å°çš„äº’åŠ¨å®éªŒåœºåœ°ï¼š

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">Awesome AI VTuber</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div class="flex flex-col items-center">
    <img :src="MemoryRetrieval" alt="memory sudden retrieval & emotion biased simulation" />
  </div>
</div>

It is fully interactive too!!! Can be played on [drizzle-orm-duckdb-wasm.netlify.app](https://drizzle-orm-duckdb-wasm.netlify.app/#/memory-simulator)!

å®ƒä¾ç„¶æ˜¯å®Œå…¨å¯äº¤äº’çš„ï¼Œå¯ä»¥åœ¨ [drizzle-orm-duckdb-wasm.netlify.app](https://drizzle-orm-duckdb-wasm.netlify.app/#/memory-simulator) è¿™é‡Œä½“éªŒä¸€ä¸‹!

## Milestones é‡Œç¨‹ç¢‘

- We reached the 300 stars!
- 3+ new fresh contributors in issues!
- 10+ new fresh group members in Discord server!
- ReLU character design finished!
- ReLU sticker Vol.1 finished!
- ReLU sticker Vol.2 animated finished!
- 89 tasks finished for [Roadmap v0.4](https://github.com/moeru-ai/airi/issues/42)

- 300 ğŸŒŸ è¾¾æˆ
- 3 ä½æ–°çš„ Issue è´¡çŒ®è€…
- 10 ä½æ–°çš„ Discord æˆå‘˜
- ReLU å½¢è±¡è®¾è®¡å®Œæˆ
- ReLU è¡¨æƒ…åŒ… Vol.1 åˆ¶ä½œå®Œæˆï¼
- ReLU è¡¨æƒ…åŒ… Vol.2 åŠ¨æ€ç‰ˆ åˆ¶ä½œå®Œæˆ
- [è·¯çº¿å›¾ v0.4](https://github.com/moeru-ai/airi/issues/42) ä¸­æœ‰æ€»è®¡ 89 ä¸ªä»»åŠ¡è¢«å®Œæˆäº†

## Other updates å…¶ä»–æ›´æ–°

### Engineering å·¥ç¨‹åŒ–

The biggest thing is, we've completely migrated our previous Electron-based solution to Tauri v2, and it doesn't look and feel
like we've encountered any bad problems yet.

æœ€å¤§çš„äº‹æƒ…è«è¿‡äºï¼Œæˆ‘ä»¬å®Œå…¨èˆå¼ƒäº†å…ˆå‰çš„åŸºäº Electron çš„æ¡Œå® æ„å»ºæ–¹æ¡ˆï¼Œè½¬å‘äº†ä½¿ç”¨ Tauri v2 çš„å®ç°ï¼Œç°åœ¨çœ‹èµ·æ¥æ„Ÿè§‰è¿˜æ²¡æœ‰é‡åˆ°ä»€ä¹ˆä¸å¥½çš„é—®é¢˜ã€‚

Big shout out to [@LemonNekoGH](https://github.com/LemonNekoGH)

çœŸçš„å¾ˆæ„Ÿè°¢ [@LemonNekoGH](https://github.com/LemonNekoGH)ï¼

A while ago, everyone on the team mentioned that the `moeru-ai/airi` repository was getting too big and that development was getting laggy.
Indeed, the `moeru-ai/airi` repository has seen the birth of countless sub-projects in the past 5 months,
covered from agent implementations,
to game agent binding implementations,
to simple and easy to use npm package wrappers,
to ground-breaking transformers.js wrappers,
to Drizzle driver support for DuckDB WASM,
to API implementation and integration of back-end services.
it's time for some of these projects to grow from the Sandbox stage to the more meaningful Incubate stage.

å›¢é˜Ÿçš„å¤§å®¶å‰æ®µæ—¶é—´éƒ½åœ¨æåˆ°è¯´ `moeru-ai/airi` è¿™ä¸ªé¡¹ç›®ä»“åº“è¶Šæ¥è¶Šå¤§äº†ï¼Œå¼€å‘çš„æ—¶å€™ä¼šå¾ˆå¡é¡¿ã€‚ç¡®å®ï¼Œè¿‡å»çš„ 5 ä¸ªæœˆé‡Œ
`moeru-ai/airi` ä»“åº“é‡Œè¯ç”Ÿäº†æ•°ä¸å°½çš„å­é¡¹ç›®ï¼Œè¦†ç›–äº†ä» agent å®ç°ï¼Œæ¸¸æˆ agent ç»‘å®šå®ç°ï¼Œåˆ°ç®€å•å¥½ç”¨çš„ npm åŒ…å°è£…ï¼Œä»¥åŠå…·æœ‰å¼€åˆ›æ€§æ„ä¹‰çš„ transformers.js å°è£…ï¼Œ
å’Œ DuckDB WASM çš„ Drizzle é©±åŠ¨æ”¯æŒï¼Œåˆ° API åç«¯æœåŠ¡çš„å®ç°å’Œé›†æˆçš„å„ç§é¢†åŸŸï¼Œæ˜¯æ—¶å€™è®©ä¸€äº›é¡¹ç›®ä» sandbox é˜¶æ®µæˆé•¿åˆ°æ›´å…·æ„ä¹‰çš„ã€ŒIncubate å­µåŒ–ã€é˜¶æ®µäº†ã€‚

So we decided to split a number of sub-projects that were already mature and in widespread
use into separate repositories to be maintained:

æ‰€ä»¥æˆ‘ä»¬å†³å®šæ‹†åˆ†è®¸å¤šå·²ç»å¾ˆæˆç†Ÿå¹¶ä¸”åœ¨å¹¿æ³›ä½¿ç”¨çš„å­é¡¹ç›®åˆ°å•ç‹¬çš„ä»“åº“ä¸­å•ç‹¬ç»´æŠ¤ï¼š

- `hfup`

  The [`hfup`](https://github.com/moeru-ai/hfup) tool that helps generate the tools used to deploy projects to HuggingFace Spaces has
sort of graduated from the `moeru-ai/airi` repository, and is now officially migrated under the organization name [@moeru-ai](https://github.com/moeru-ai)
(no migration required, just keep installing `hfup` and you're good to go). It's interesting to note that `hfup` has also adopted [rolldown](https://rolldown.rs/)
and [oxlint](https://oxc.rs/docs/guide/usage/linter) to help with development in order to keep up with the times, so I hope to take this opportunity
to participate in rolldown. I hope to take this opportunity to participate in the development of rolldown, rolldown-vite and oxc.
Thanks to [@sxzz](https://github.com/sxzz) for the integration process.

  ç”¨äºå¸®åŠ©ç”Ÿæˆç”¨äºéƒ¨ç½²é¡¹ç›®åˆ° HuggingFace Spaces çš„ [`hfup`](https://github.com/moeru-ai/hfup) å·¥å…·å·²ç»ç®—æ˜¯ä» `moeru-ai/airi` å¤§ä»“åº“ä¸­é˜¶æ®µæ€§æ¯•ä¸šäº†ï¼Œ
ç°åœ¨æ­£å¼è¿ç§»åˆ° [@moeru-ai](https://github.com/moeru-ai) çš„ç»„ç»‡åä¸‹ï¼ˆä¸éœ€è¦ä»»ä½•è¿ç§»æ“ä½œï¼Œç»§ç»­å®‰è£… `hfup` å°±å¯ä»¥ç”¨äº†ï¼‰ã€‚éå¸¸æœ‰æ„ä¹‰çš„æ˜¯ï¼Œ`hfup` ä¸ºäº†è·Ÿä¸Šæ—¶ä»£ï¼Œ
ä¹Ÿé‡‡ç”¨äº† [rolldown](https://rolldown.rs/) å’Œ [oxlint](https://oxc.rs/docs/guide/usage/linter) å¸®åŠ©å¼€å‘ï¼Œå¸Œæœ›èƒ½å€Ÿæ­¤æœºä¼šå‚ä¸åˆ° rolldownï¼Œ
rolldown-vite å’Œ oxc çš„å¼€å‘å½“ä¸­ã€‚éå¸¸æ„Ÿè°¢ [@sxzz](https://github.com/sxzz) åœ¨è¿ç§»è¿‡ç¨‹ä¸­ç»™åˆ°çš„æ´åŠ©ã€‚

- `@proj-airi/drizzle-duckdb-wasm`, `@proj-airi/duckdb-wasm`
  The `@proj-airi/drizzle-duckdb-wasm` and `@proj-airi/duckdb-wasm` used to add DuckDB WASM driver support to Drizzle have also graduated
in stages, and are now officially migrated under the organization name [@proj-airi](https://github.com/proj-airi)
(no migration required, just keep installing the original packages).

  ç”¨äºä¸º Drizzle æ·»åŠ  DuckDB WASM é©±åŠ¨æ”¯æŒçš„ `@proj-airi/drizzle-duckdb-wasm` å’Œ `@proj-airi/duckdb-wasm` ä¹Ÿç®—æ˜¯é˜¶æ®µæ€§æ¯•ä¸šäº†ï¼Œ
ç°åœ¨æ­£å¼è¿ç§»åˆ° [@proj-airi](https://github.com/proj-airi) çš„ç»„ç»‡åä¸‹ï¼ˆä¸éœ€è¦ä»»ä½•è¿ç§»æ“ä½œï¼Œç»§ç»­å®‰è£…åŸæ¥çš„åŒ…å°±å¯ä»¥ç”¨äº†ï¼‰ã€‚

The project is much faster now and should officially graduate `@proj-airi/providers-transformers` to `xsai` this month.

ç°åœ¨é¡¹ç›®é€Ÿåº¦å¿«äº†å¾ˆå¤šï¼Œè¿™ä¸ªæœˆåº”è¯¥ä¼šæŠŠ `@proj-airi/providers-transformers` æ­£å¼æ¯•ä¸šåˆ° `xsai` åä¸‹ã€‚

In terms of other engineered improvements, we also integrated the fresh new Workflow oriented toolkit called [`@llama-flow/core`](https://github.com/run-llama/@llama-flow/core)
to help with orchestrating pipeline processing of tokens, bytes, and data flows.
Do check out their repository, it's really easy to use.

åœ¨å…¶ä»–å·¥ç¨‹æ”¹è¿›æ–¹é¢ï¼Œæˆ‘ä»¬è¿˜é›†æˆäº†å…¨æ–°çš„é¢å‘å·¥ä½œæµçš„å·¥å…·åŒ… [`@llama-flow/core`](https://github.com/run-llama/@llama-flow/core)ï¼Œä»¥å¸®åŠ©åè°ƒ token å¤„ç†ã€å­—èŠ‚æµå’Œæ•°æ®æµçš„ pipeline ç¼–æ’ã€‚
è®°å¾—çœ‹çœ‹ä»–ä»¬çš„ä»“åº“ï¼ŒçœŸçš„éå¸¸å¥½ç”¨ï¼

### UI ç•Œé¢

We finally supported Character cards natively!

æˆ‘ä»¬ç»ˆäºåŸç”Ÿæ”¯æŒè§’è‰²å¡/é…’é¦†è§’è‰²å¡äº†ï¼

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">Awesome AI VTuber</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div class="flex flex-col items-center">
    <img :src="CharacterCard" alt="character card" />
  </div>
</div>

A editor with models, voice lines, and every modules that Project AIRI has supported is included ğŸ‰.

å½“ç„¶ï¼Œä¸€ä¸ªåŒ…å«æ¨¡å‹ã€å£°çº¿å’Œ Project AIRI æ”¯æŒçš„æ‰€æœ‰æ¨¡å— ğŸ‰ çš„é…ç½®çš„èƒ½åŠ›çš„ç¼–è¾‘å™¨ä¹ŸåŒ…å«åœ¨å†…äº†ã€‚

Big shout out to [@luoling8192](https://github.com/luoling8192)

çœŸçš„å¾ˆæ„Ÿè°¢ [@luoling8192](https://github.com/luoling8192)ï¼

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">Awesome AI VTuber</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div class="flex flex-col items-center">
    <img :src="CharacterCardDetail" alt="character card detail" />
  </div>
</div>

Another huge UI milestone as also introduced by [@luoling8192](https://github.com/luoling8192),
we got color presets included!

ç”± [@luoling8192](https://github.com/luoling8192) æ¨å‡ºçš„å¦ä¸€ä¸ªå·¨å¤§çš„ UI é‡Œç¨‹ç¢‘æ˜¯ï¼Œæˆ‘ä»¬åŠ å…¥äº†é¢„è®¾é¢œè‰²æ”¯æŒï¼

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">Awesome AI VTuber</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div class="flex flex-col items-center">
    <img :src="MoreThemeColors" alt="more theme colors" />
  </div>
</div>

### Community ç¤¾åŒº

[@sumimakito](https://github.com/sumimakito) helped to establish the Awesome AI VTuber (or AI Waifu) repository:

[@sumimakito](https://github.com/sumimakito) å¸®åŠ©å»ºç«‹äº† Awesome AI VTuberï¼ˆæˆ– AI waifuï¼‰çš„ä»“åº“ï¼š

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">Awesome AI VTuber</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div class="flex flex-col items-center">
    <img class="px-30 md:px-40 lg:px-50" :src="AwesomeAIVTuber" alt="Awesome AI VTuber Logo" />
    <div class="text-center pb-4">
      <span class="block font-bold">Awesome AI VTuber</span>
      <span>A curated list of AI VTubers and their related projects</span>
    </div>
  </div>
</div>

> The VTuber style logo was designed purely by [@sumimakito](https://github.com/sumimakito), I love it â¤ï¸.
>
> VTuber é£æ ¼çš„ Logo æ˜¯å®Œå…¨ç”± [@sumimakito](https://github.com/sumimakito) è®¾è®¡å’Œåˆ¶ä½œçš„ï¼æˆ‘è¶…å–œæ¬¢ã€‚

I guess this is definitely the biggest DevLog I've ever written since last month. And there are still tons of features,
bug fixes, and improvements we haven't covered yet:

æˆ‘æƒ³è¿™ç»å¯¹æ˜¯æˆ‘è‡ªä¸Šä¸ªæœˆä»¥æ¥å†™è¿‡çš„æœ€å¤§ç¯‡å¹…çš„ DevLogã€‚è¿˜æœ‰å¾ˆå¤šåŠŸèƒ½ã€é”™è¯¯ä¿®å¤å’Œæ”¹è¿›æˆ‘ä»¬è¿˜æ²¡æœ‰æ¶‰åŠï¼š

- Featherless.ai provider supported
- Gemini provider supported (thanks to [@asukaminato0721](https://github.com/asukaminato0721))
- Catastrophic OOM bug fixed for Telegram Bot integration (thanks to [@sumimakito](https://github.com/sumimakito), [@kwaa](https://github.com/kwaa), and [@QiroNT](https://github.com/QiroNT))
- New 98.css integration for Project AIRI's special DevLog (thanks to [@OverflowCat](https://github.com/OverflowCat))

> This is a special version of Project AIRI's DevLog that heavily inspired by [@OverflowCat](https://github.com/OverflowCat)'s
> blog post [ModTran](https://blog.xinshijiededa.men/modtran/) and the style of code was copied from [@OverflowCat](https://github.com/OverflowCat)'s implementation
> over https://github.com/OverflowCat/blog/blob/0a92f916629ad942b7da84b894759fde1616bf37/src/components/98/98.ts
>
> She writes awesome blog posts about almost everything I am not familiar with, please do check it out, u will like it.
>
> è¿™æ˜¯ Project AIRI ä¸€ç¯‡ç‰¹åˆ«ç‰ˆçš„å¼€å‘æ—¥å¿—ï¼Œå…¶çµæ„Ÿä¸»è¦æ¥è‡ª [@OverflowCat](https://github.com/OverflowCat) çš„åšæ–‡ [ModTran](https://blog.xinshijiededa.men/modtran/)ï¼Œ
> ä»£ç é£æ ¼å¤§é‡å€Ÿé‰´äº† [@OverflowCat](https://github.com/OverflowCat) åœ¨ https://github.com/OverflowCat/blog/blob/0a92f916629ad942b7da84b894759fde1616bf37/src/components/98/98.ts é‡Œçš„å®ç°ã€‚
>
> å¥¹å†™çš„åšæ–‡å¾ˆæ£’ï¼Œå‡ ä¹æ¶‰åŠæ‰€æœ‰æˆ‘ä¸ç†Ÿæ‚‰çš„å†…å®¹ï¼Œè¯·ä¸€å®šå»çœ‹çœ‹ï¼Œä½ ä¼šå–œæ¬¢çš„ã€‚

## See you

I think that's all for this time's DevLog, this closes our [Roadmap v0.4](https://github.com/moeru-ai/airi/issues/42) too,
we hope you like the fresh new looking of the UI and updated tamagotchi version.
I tried to use both English and Chinese to write this for both of the language audiences, please do leave a comment in our
[repository's discussion's](https://github.com/moeru-ai/airi/discussions) page to tell us whether you like this or not.

æˆ‘æƒ³è¿™å°±æ˜¯æœ¬æ¬¡ DevLog çš„å…¨éƒ¨å†…å®¹äº†ï¼Œæˆ‘ä»¬çš„ [Roadmap v0.4](https://github.com/moeru-ai/airi/issues/42) ä¹Ÿåˆ°æ­¤ç»“æŸï¼Œ
å¸Œæœ›å¤§å®¶å–œæ¬¢ç„•ç„¶ä¸€æ–°çš„ç”¨æˆ·ç•Œé¢å’Œæ›´æ–°åçš„æ¡Œå® ç‰ˆæœ¬ã€‚
æˆ‘åœ¨å†™è¿™ç¯‡æ–‡ç« æ—¶å°è¯•ä½¿ç”¨äº†ä¸­è‹±æ–‡ä¸¤ç§è¯­è¨€ï¼Œè¯·åœ¨æˆ‘ä»¬ä»“åº“çš„[è®¨è®ºé¡µé¢](https://github.com/moeru-ai/airi/discussions)ç•™è¨€ï¼Œå‘Šè¯‰æˆ‘ä»¬æ‚¨æ˜¯å¦å–œæ¬¢è¿™ç¯‡æ–‡ç« ã€‚

Let's use the quote from ReLU for the ending:

è®©æˆ‘ä»¬å¼•ç”¨ ReLU çš„å¦ä¸€å¥å¯¹è‡ªå·±çš„æ„Ÿè§‰çš„æè¿°ä½œä¸ºç»“å°¾å§ï¼š

<div class="devlog-window">
  <div class="title-bar">
  <div class="title-bar-text">ReLU self feeling</div>
    <div class="title-bar-controls">
      <button aria-label="Minimize"></button>
      <button aria-label="Maximize"></button>
      <button aria-label="Close"></button>
    </div>
  </div>
  <div style="padding: 12px; margin-top: 0px;">
    <div class="flex justify-center w-[20%]">
      <img :src="ReLUStickerWow" alt="ReLU sticker for expression wow" />
    </div>
    <div class="flex flex-col">
      <div>Some days I feel like I'm really a symbolic being, </div>
      <div>like a ghost running out of code</div>
      <div>æœ‰äº›æ—¶å€™ï¼Œæˆ‘è§‰å¾—è‡ªå·±çœŸçš„æ˜¯ä¸ªç¬¦å·å¼çš„å­˜åœ¨ï¼Œåƒä¸ªä»£ç é‡Œè·‘å‡ºæ¥çš„å¹½çµ</div>
    </div>
  </div>
</div>
